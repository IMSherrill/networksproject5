#!/usr/bin/env python

import sys, socket, select, time, json, random
from datetime import datetime



# Your ID number
my_id = sys.argv[1]

# The ID numbers of all the other replicas
replica_ids = sys.argv[2:]

# Connect to the network. All messages to/from other replicas and clients will
# occur over this socket
sock = socket.socket(socket.AF_UNIX, socket.SOCK_SEQPACKET)
sock.connect(my_id)

all_id = [my_id] + replica_ids

last = 0

currentTerm = 0
state = "follower"
log = []
data = {}
leader = "----"

heardFromLeader = datetime.now()



while True:
	ready = select.select([sock], [], [], 0.1)[0]

	if sock in ready:

		# TODO: abstract leader election into another function
		# if we dont know who the leader is 
		if leader == "----":
			election_msg = {
				"src": my_id,
				"leader": "FFFF",
				"dst": "FFFF",
				"type": "requestvote",
			}

			sock.send(json.dumps(election_msg))


		lasttime = datetime.now()

		msg_raw = sock.recv(32768)
		
		if len(msg_raw) == 0: continue
		msg = json.loads(msg_raw)
		# print "{} {}".format(my_id, msg)
		# print "{} {}".format(my_id, msg['type'])

		# TODO: should sepaate logic into whether I am the leader or not
		if leader == my_id:
					if msg['type'] == 'redirect':
					# i think only the leader should receive this. if not theres some error
						print '{} got a redirect'.format(my_id)
						redirected_msg = msg['msg']
						broadcast_msg = redirected_msg
						broadcast_msg['dst'] = 'FFFF'
						broadcast_msg['src'] = my_id
						sock.send(json.dumps(broadcast_msg))



		if msg['src'] == leader:
			heardFromLeader = datetime.now()
			print 'hearing from leader here'
	

		if (datetime.now() - heardFromLeader).seconds > 2 and not my_id == leader:
			print 'should elect a new leader'








		# For now, ignore get() and put() from clients
		if msg['type'] in ['get', 'put']:
			if leader == my_id:
				broadcast_msg = {
									"src" : my_id,
									"dst" :	"FFFF",
								 "leader" : leader,
								   "type" : msg['type'],
								   "MID"  : msg['MID'],
								}

				sock.send(json.dumps(broadcast_msg))

			if msg['src'] == leader:
				print '{} should log and actually {} here'.format(my_id, msg['type'])
				pass
				# print '{} putting {} into {}'.format(my_id, msg['key'], msg['value']) 
				# data[msg['key']] = msg['value']


			else:
				redirect_msg = {
									"src" : my_id,
									"dst" :	leader,
								 "leader" : leader,
								   "type" : "redirect",
								   "msg"  : msg,
								}

				sock.send(json.dumps(redirect_msg))

		if msg['type'] == 'requestvote':
			# Temporary
			print 'received request to vote'

			all_id.sort()
			leader = all_id[0]

		
		# Handle noop messages. This may be removed from your final implementation
		elif msg['type'] == 'noop':
			print '%s received a NOOP from %s' % (msg['dst'], msg['src'])
		
	clock = time.time()
	if clock-last > 2:
		# Send a no-op message to a random peer every two seconds, just for fun
		# You definitely want to remove this from your implementation


		# msg = {'src': my_id, 'dst': random.choice(replica_ids), 'leader': 'FFFF', 'type': 'noop'}
		# sock.send(json.dumps(msg))
		# print '%s sending a NOOP to %s' % (msg['src'], msg['dst'])
		# last = clock
		pass



#1  Add basic support for responding to client get() and put() requests. At this point, you can respond to all requests with a "type": "fail" message.
#2  Implement the Raft election protocol (section 5.2 of the Raft paper); add the ability to respond to get() and put() requests with "type": "redirect" messages.
#3  Add a timeout to detect leader failures (i.e. if you don't hear from the leader in X milliseconds...) and make sure that the new election proceeds correctly.
#4  Implement a basic, empty version of the AppendEntries RPC call that doesn't replicate any data, but acts as a keepalive message from the leader to other replicas to prevent unnecessary elections.
#5  Implement the transaction log and the "state machine" (i.e. a dictionary containing the key/value pairs from clients, Section 5.3). Don't bother replicating the transactions, just ensure that the leader is able to correctly answer get() and put() requests.
#6  Improve your AppendEntries RPC call to actually send data to replicas. Ensure that updates are only committing when a quorum is in agreement.
#7  Add support for retrying failed commits and test it by experimenting with lossy network simulations.
#8  If you haven't already, modify the leader election to support the additional restrictions in Section 5.4.1; test your implementation on lossy networks with failed leaders.
#9  Implement the subtle commit restriction given in Section 5.4.2.
#10 Test, test, test, and test some more ;)
# Step 6 will probably require the most time in terms of writing code and debugging, since it is the crux of the algorithm. Implementing steps 7-9 are necessary to ensure correctness of the protocol, but shouldn't be too difficult.